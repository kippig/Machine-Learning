{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a KNN model, finds the optimal value of k, and reports f1 score and log loss.  \n",
    "\n",
    "The notebook can use either the full set of training and test data from Kaggle, or on 80% of the training data and 20% held back development data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip data files into the \"csv\" subdirectory\n",
    "\n",
    "# **IMPORTANT**  This will overwrite existing files in the \"csv\" folder in your local repo\n",
    "# with the most recent data files from the data.zip file\n",
    "\n",
    "# Unzip 80% training data\n",
    "unzip_training_data = zipfile.ZipFile(\"data_subset.zip\", \"r\")\n",
    "unzip_training_data.extractall()\n",
    "unzip_training_data.close()\n",
    "\n",
    "# Unzip development and training data\n",
    "unzip_test_data = zipfile.ZipFile(\"testing.zip\", \"r\")\n",
    "unzip_test_data.extractall()\n",
    "unzip_test_data.close()\n",
    "\n",
    "# Unzip full set of training data for creating predictions to submit to Kaggle\n",
    "unzip_all_data = zipfile.ZipFile(\"data.zip\", \"r\")\n",
    "unzip_all_data.extractall()\n",
    "unzip_all_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load these csv files into numpy arrays for testing on development data\n",
    "train_data = np.loadtxt('csv/train_data.csv', delimiter=\",\")\n",
    "train_labels = np.loadtxt('csv/train_labels.csv', dtype=str, delimiter=\",\")\n",
    "dev_data = np.loadtxt('csv/dev_data.csv', delimiter=\",\")\n",
    "dev_labels = np.loadtxt('csv/dev_labels.csv', dtype=str, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load these csv files into numpy arrays for creating predictions to submit to Kaggle\n",
    "train_data_all = np.loadtxt('csv/train_data_all.csv', delimiter=\",\")\n",
    "train_labels_all = np.loadtxt('csv/train_labels_all.csv', dtype=str, delimiter=\",\")\n",
    "test_data_all = np.loadtxt('csv/test_data_all.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape is (702439, 58)\n",
      "train_labels shape is (702439,)\n",
      "dev_data shape is (175610, 58)\n",
      "dev_labels shape is (175610,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes to compare before and after csv conversion\n",
    "print(\"train_data shape is\", train_data.shape)\n",
    "print(\"train_labels shape is\", train_labels.shape)\n",
    "print(\"dev_data shape is\", dev_data.shape)\n",
    "print(\"dev_labels shape is\", dev_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_all shape is (878049, 58)\n",
      "train_labels_all shape is (878049,)\n",
      "test_data_all shape is (884262, 58)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data_all shape is\", train_data_all.shape)\n",
    "print(\"train_labels_all shape is\", train_labels_all.shape)\n",
    "print(\"test_data_all shape is\", test_data_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IF there are additional changes to make to the data for this model\n",
    "# that would be easier to do in pandas, uncomment and run this code. \n",
    "# This model works the same whether the data is in numpy or pandas, so presumably so do other models\n",
    "\n",
    "#train_data = pd.DataFrame(train_data)\n",
    "#train_labels = pd.DataFrame(train_labels)\n",
    "#dev_data = pd.DataFrame(dev_data)\n",
    "#dev_labels = pd.DataFrame(dev_labels)\n",
    "#train_data_all = pd.DataFrame(train_data_all)\n",
    "#train_labels_all = pd.DataFrame(train_labels_all)\n",
    "#test_data_all = pd.DataFrame(test_data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up functions for training models and finding optimal value of k and reporting accuracy\n",
    "\n",
    "def TrainKNN(data, labels, test_data, k=5):\n",
    "    \"\"\"This function takes in training data and labels, testing data,\n",
    "    and can accept different values of k. \n",
    "    It trains a KNN model and returns the model and predicted probabilities.\n",
    "    \"\"\"\n",
    "    KNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN.fit(data, labels)\n",
    "    pp = KNN.predict_proba(test_data)\n",
    "    return KNN, pp\n",
    "\n",
    "def find_k(data, labels, dev_data, dev_labels, k_values):\n",
    "    \"\"\"Find optimal value of k.  \n",
    "    \n",
    "    Note that this cannot be used on test data from Kaggle \n",
    "    because we do not have labels for that data.  This function is intended to only be used\n",
    "    in the development stage with the development data.\n",
    "    \"\"\"\n",
    "    for k in k_values:\n",
    "        \n",
    "        KNN, pp = TrainKNN(data, labels, dev_data, k)\n",
    "        predictions = KNN.predict(dev_data)\n",
    "        f1 = metrics.f1_score(dev_labels, predictions, average = \"weighted\")\n",
    "        logloss = metrics.log_loss(dev_labels, pp)\n",
    "        \n",
    "        # Print F1 score and log loss for each value of k\n",
    "        print(\"For k =\", k, \"the F1 score is\", round(f1, 4), \"and the Log Loss score is\", round(logloss, 4))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the optimal value of k using the 80% training data and the development data\n",
    "# This takes too long to run with large values of k on the larger sized data set\n",
    "k_values = [1, 7]\n",
    "find_k(train_data, train_labels, dev_data, dev_labels, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_values = [15]\n",
    "find_k(train_data, train_labels, dev_data, dev_labels, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_values = [25]\n",
    "find_k(train_data, train_labels, dev_data, dev_labels, k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0861679843\n"
     ]
    }
   ],
   "source": [
    "# Can also train the model with single value of k with 80% training data and development data\n",
    "k = 2\n",
    "KNN, pp = TrainKNN(train_data, train_labels, dev_data, k)\n",
    "logloss = metrics.log_loss(dev_labels, pp)\n",
    "print(logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before submitting to Kaggle, run the model on the full set of training data and test data\n",
    "# using the optimal value for the model\n",
    "k = use optimal value here\n",
    "KNN, pp = TrainKNN(train_data_all, train_labels_all, test_data_all, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up predictions for submission to Kaggle\n",
    "headers = [\"ARSON\",\"ASSAULT\",\"BAD CHECKS\",\"BRIBERY\",\"BURGLARY\",\"DISORDERLY CONDUCT\",\"DRIVING UNDER THE INFLUENCE\",\n",
    "           \"DRUG/NARCOTIC\",\"DRUNKENNESS\",\"EMBEZZLEMENT\",\"EXTORTION\",\"FAMILY OFFENSES\",\"FORGERY/COUNTERFEITING\",\n",
    "           \"FRAUD\",\"GAMBLING\",\"KIDNAPPING\",\"LARCENY/THEFT\",\"LIQUOR LAWS\",\"LOITERING\",\"MISSING PERSON\",\"NON-CRIMINAL\",\n",
    "           \"OTHER OFFENSES\",\"PORNOGRAPHY/OBSCENE MAT\",\"PROSTITUTION\",\"RECOVERED VEHICLE\",\"ROBBERY\",\"RUNAWAY\",\n",
    "           \"SECONDARY CODES\",\"SEX OFFENSES FORCIBLE\",\"SEX OFFENSES NON FORCIBLE\",\"STOLEN PROPERTY\",\"SUICIDE\",\n",
    "           \"SUSPICIOUS OCC\",\"TREA\",\"TRESPASS\",\"VANDALISM\",\"VEHICLE THEFT\",\"WARRANTS\",\"WEAPON LAWS\"]\n",
    "data = pd.DataFrame(data=pp, \n",
    "                    index=[x for x in range(len(test_data_all))], \n",
    "                    columns=headers)\n",
    "data.columns.name =\"Id\"\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create zipped csv file for Kaggle\n",
    "#### Update the filename first in all lines of the following code\n",
    "Add something unique after our names to avoid overwriting other submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('Williams_Gascoigne_Vignola_.csv', index_label = \"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_probs = zipfile.ZipFile(\"Williams_Gascoigne_Vignola_.zip\", \"w\")\n",
    "zip_probs.write(\"Williams_Gascoigne_Vignola_.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_probs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from previous datasets and/or model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from dataset submitted as baseline (where the only feature engineering was Label Encoding into numeric features):  \n",
    "(Baseline submission set k=1)\n",
    "\n",
    "For k = 1 the F1 score is 0.2006  \n",
    "For k = 1 the Log Loss score is 27.6013  \n",
    "For k = 3 the F1 score is 0.1552  \n",
    "For k = 3 the Log Loss score is 22.3636  \n",
    "For k = 5 the F1 score is 0.154  \n",
    "For k = 5 the Log Loss score is 19.0689  \n",
    "For k = 7 the F1 score is 0.1533  \n",
    "For k = 7 the Log Loss score is 16.6886  \n",
    "For k = 9 the F1 score is 0.1526  \n",
    "For k = 9 the Log Loss score is 14.8641  \n",
    "For k = 11 the F1 score is 0.1515  \n",
    "For k = 11 the Log Loss score is 13.3879  \n",
    "For k = 15 the F1 score is 0.1492  \n",
    "For k = 15 the Log Loss score is 11.2378  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
