{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train our initial machine learning model and then implement gradual training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 10  3  2 12  1 13  6  8  5  7  0 13  8 22  9 11  6  4 23 15  0 16 21 14\n",
      " 19 18 20]\n"
     ]
    }
   ],
   "source": [
    "airline = ['TZ', 'FL', 'AS', 'AQ', 'HP', 'AA', 'MQ', 'DH', 'EV', 'CO', 'DL', '9E', 'MQ', 'EV', 'XE', 'F9', 'HA', 'DH', 'B6', 'YV', 'NW', '9E', 'OO', 'WN', 'NK', 'US', 'UA', 'VX']\n",
    "airlineEncoder = LabelEncoder()\n",
    "airlineEncoder.fit(airline)\n",
    "joblib.dump(airlineEncoder, \"Airline_Encoder.pkl\", protocol = 2)\n",
    "print(airlineEncoder.transform(airline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADK', 'ANC', 'ANI', 'BRW', 'BET', 'CDV', 'SCC', 'DLG', 'FAI', 'GST', 'JNU', 'KTN', 'AKN', 'ADQ', 'OTZ', 'OME', 'PSG', 'SIT', 'KSM', 'DUT', 'WRG', 'YAK', 'BHM', 'DHN', 'HSV', 'MOB', 'MGM', 'XNA', 'FSM', 'LIT', 'TXK', 'PPG', 'IFP', 'FLG', 'GCN', 'PHX', 'TUS', 'ACV', 'BFL', 'BUR', 'CIC', 'CCR', 'CEC', 'FAT', 'IPL', 'IYK', 'LGB', 'LAX', 'MMH', 'MOD', 'MRY', 'OAK', 'ONT', 'OXR', 'PSP', 'PMD', 'RDD', 'SMF', 'SAN', 'SFO', 'SJC', 'SBP', 'SNA', 'SBA', 'SMX', 'STS', 'TVL', 'SCK', 'VIS', 'ASE', 'COS', 'DEN', 'DRO', 'EGE', 'GJT', 'GUC', 'MTJ', 'PUB', 'TEX', 'HVN', 'BDL', 'DCA', 'IAD', 'ILG', 'DAB', 'FLL', 'RSW', 'GNV', 'JAX', 'EYW', 'MTH', 'MLB', 'MIA', 'APF', 'MCO', 'ECP', 'PNS', 'PGD', 'SRQ', 'PIE', 'TLH', 'TPA', 'VPS', 'PBI', 'ABY', 'ATL', 'AGS', 'BQK', 'CSG', 'MCN', 'SAV', 'VLD', 'GUM', 'ITO', 'HNL', 'OGG', 'KOA', 'MKK', 'LNY', 'LIH', 'CID', 'DSM', 'DBQ', 'SUX', 'ALO', 'BOI', 'SUN', 'IDA', 'LWS', 'PIH', 'TWF', 'BMI', 'CMI', 'MDW', 'ORD', 'RFD', 'MLI', 'PIA', 'SPI', 'EVV', 'FWA', 'IND', 'SBN', 'GCK', 'HYS', 'MHK', 'FOE', 'ICT', 'CVG', 'LEX', 'SDF', 'PAH', 'AEX', 'BTR', 'LFT', 'LCH', 'MLU', 'MSY', 'SHV', 'BOS', 'HYA', 'ACK', 'MVY', 'ORH', 'BWI', 'BGR', 'PWM', 'APN', 'DET', 'DTW', 'ESC', 'FNT', 'GRR', 'CMX', 'IMT', 'AZO', 'LAN', 'MKG', 'PLN', 'MBS', 'CIU', 'TVC', 'BJI', 'BRD', 'DLH', 'HIB', 'INL', 'MSP', 'RST', 'STC', 'COU', 'JLN', 'MKC', 'MCI', 'SGF', 'STL', 'CBM', 'GTR', 'GLH', 'GPT', 'PIB', 'JAN', 'MEI', 'TUP', 'BIL', 'BZN', 'BTM', 'GTF', 'HLN', 'GPI', 'MSO', 'WYS', 'AVL', 'CLT', 'FAY', 'GSO', 'HKY', 'OAJ', 'ISO', 'EWN', 'SOP', 'RDU', 'ILM', 'BIS', 'DVL', 'DIK', 'FAR', 'RDR', 'GFK', 'JMS', 'MIB', 'MOT', 'ISN', 'GRI', 'LNK', 'LBF', 'OMA', 'BFF', 'MHT', 'ACY', 'EWR', 'TTN', 'ABQ', 'FMN', 'HOB', 'ROW', 'SAF', 'EKO', 'LAS', 'RNO', 'ALB', 'BGM', 'BUF', 'ELM', 'ITH', 'JFK', 'LGA', 'ISP', 'SWF', 'IAG', 'PBG', 'ROC', 'SYR', 'ART', 'HPN', 'CAK', 'CLE', 'CMH', 'DAY', 'TOL', 'LAW', 'OKC', 'TUL', 'EUG', 'LMT', 'MFR', 'OTH', 'PDX', 'RDM', 'SLE', 'ABE', 'ERI', 'MDT', 'LBE', 'PHL', 'PIT', 'AVP', 'BQN', 'MAZ', 'PSE', 'SJU', 'PVD', 'CHS', 'CAE', 'FLO', 'GSP', 'MYR', 'ABR', 'PIR', 'RCA', 'RAP', 'FSD', 'TRI', 'CHA', 'TYS', 'MEM', 'BNA', 'ABI', 'AMA', 'AUS', 'BPT', 'BRO', 'CLL', 'CRP', 'DAL', 'TKI', 'DFW', 'DRT', 'ELP', 'GRK', 'HRL', 'EFD', 'IAH', 'HOU', 'ILE', 'LRD', 'GGG', 'LBB', 'MFE', 'MAF', 'SJT', 'SAT', 'TYR', 'VCT', 'ACT', 'SPS', 'CDC', 'CNY', 'OGD', 'PVU', 'SLC', 'SGU', 'VEL', 'ENV', 'CHO', 'LYH', 'PHF', 'ORF', 'RIC', 'ROA', 'SHD', 'STT', 'STX', 'BTV', 'BLI', 'MWH', 'PSC', 'BFI', 'SEA', 'SKA', 'GEG', 'YKM', 'ATW', 'EAU', 'GRB', 'LSE', 'MSN', 'MKE', 'CWA', 'RHI', 'CRW', 'CKB', 'HTS', 'LWB', 'CPR', 'CYS', 'COD', 'GCC', 'JAC', 'LAR', 'RKS', 'FCA', 'PFN', 'BKG', 'CLD', 'HDN', 'HHH', 'MQT', 'AZA', 'ROP', 'SPN', 'UST', 'SCE', 'UTM', 'YAP', 'YUM']\n"
     ]
    }
   ],
   "source": [
    "#Things to Label Encode... All Airports, All Tail numbers\n",
    "airports = pd.read_csv(\"Airport_to_Weather_Stations.txt\")[\"LocationID\"].tolist() + ['FCA', 'PFN', 'BKG','CLD', 'HDN', 'HHH', 'MQT', 'AZA', 'ROP', 'SPN', \n",
    "                'UST', 'SCE', 'UTM', 'YAP', 'YUM']\n",
    "airportEncoder = LabelEncoder()\n",
    "airportEncoder.fit(airports)\n",
    "joblib.dump(airportEncoder, \"Airport_Encoder.pkl\", protocol = 2)\n",
    "print(airports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7332 8265 6797 ..., 7758 4970 3054]\n"
     ]
    }
   ],
   "source": [
    "#Encode TailNumbers\n",
    "TailNumbers = pd.read_csv(\"Final_Tail_Number_List.txt\", header = None)[0].tolist()\n",
    "TailEncoder = LabelEncoder()\n",
    "TailEncoder.fit(TailNumbers)\n",
    "joblib.dump(TailEncoder, \"Tail_Number_Encoder.pkl\", protocol = 2)\n",
    "print(TailEncoder.transform(TailNumbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"Final_historical_data.csv\"\n",
    "#f = open(filename)\n",
    "#n = sum(1 for line in f) #number of records in file (excludes header)\n",
    "#print(n)\n",
    "#f.close()\n",
    "n = 34962162 #Number of rows!!\n",
    "s = 1000000 #desired sample size\n",
    "skip = sorted(random.sample(range(0,n+1),n-s)) #the 0-indexed header will not be included in the skip list\n",
    "df = pd.read_csv(filename, skiprows=skip, names = [\"Airline\", \"Year\", \"Month\", \"Day\"\n",
    "                                    ,\"Tail\", \"Source\", \"Destination\",  \"Departure_hour\", \"Departure_minute\"\n",
    "                                    , \"Delay\", \"Station\", \"Previous_Delay\", 'PRCP', 'SNOW', 'TMAX', 'TMIN'])\n",
    "\n",
    "df.to_csv(\"Random_Sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"Airline\"] = airlineEncoder.transform(df[\"Airline\"])\n",
    "df['Source'] = airportEncoder.transform(df['Source'])\n",
    "df['Destination']  = airportEncoder.transform(df['Destination'])\n",
    "df['Tail'] = TailEncoder.transform(df['Tail'])\n",
    "df['Y'] = df['Delay'] > 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(df[[\"Airline\", \"Year\", \"Month\", \"Day\", \"Source\", \n",
    "           \"Destination\",  \"Departure_hour\", \"Departure_minute\", \"Previous_Delay\", 'PRCP', 'SNOW', 'TMAX', 'TMIN']], df['Y'])\n",
    "joblib.dump(LR, \"LR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomization order complete.\n",
      "0 loaded pd dataframe\n",
      "Fitted lines 500000\n",
      "1 loaded pd dataframe\n",
      "Fitted lines 1000000\n",
      "2 loaded pd dataframe\n",
      "Fitted lines 1500000\n",
      "3 loaded pd dataframe\n",
      "Fitted lines 2000000\n",
      "4 loaded pd dataframe\n",
      "Fitted lines 2500000\n",
      "5 loaded pd dataframe\n",
      "Fitted lines 3000000\n",
      "6 loaded pd dataframe\n",
      "Fitted lines 3500000\n",
      "7 loaded pd dataframe\n",
      "Fitted lines 4000000\n",
      "8 loaded pd dataframe\n",
      "Fitted lines 4500000\n",
      "9 loaded pd dataframe\n",
      "Fitted lines 5000000\n",
      "10 loaded pd dataframe\n",
      "Fitted lines 5500000\n",
      "11 loaded pd dataframe\n",
      "Fitted lines 6000000\n",
      "12 loaded pd dataframe\n",
      "Fitted lines 6500000\n",
      "13 loaded pd dataframe\n",
      "Fitted lines 7000000\n",
      "14 loaded pd dataframe\n",
      "Fitted lines 7500000\n",
      "15 loaded pd dataframe\n",
      "Fitted lines 8000000\n",
      "16 loaded pd dataframe\n",
      "Fitted lines 8500000\n",
      "17 loaded pd dataframe\n",
      "Fitted lines 9000000\n",
      "18 loaded pd dataframe\n",
      "Fitted lines 9500000\n",
      "19 loaded pd dataframe\n",
      "Fitted lines 10000000\n",
      "20 loaded pd dataframe\n",
      "Fitted lines 10500000\n",
      "21 loaded pd dataframe\n",
      "Fitted lines 11000000\n",
      "22 loaded pd dataframe\n",
      "Fitted lines 11500000\n",
      "23 loaded pd dataframe\n",
      "Fitted lines 12000000\n",
      "24 loaded pd dataframe\n",
      "Fitted lines 12500000\n",
      "25 loaded pd dataframe\n",
      "Fitted lines 13000000\n",
      "26 loaded pd dataframe\n",
      "Fitted lines 13500000\n",
      "27 loaded pd dataframe\n",
      "Fitted lines 14000000\n",
      "28 loaded pd dataframe\n",
      "Fitted lines 14500000\n",
      "29 loaded pd dataframe\n",
      "Fitted lines 15000000\n",
      "30 loaded pd dataframe\n",
      "Fitted lines 15500000\n",
      "31 loaded pd dataframe\n",
      "Fitted lines 16000000\n",
      "32 loaded pd dataframe\n",
      "Fitted lines 16500000\n",
      "33 loaded pd dataframe\n",
      "Fitted lines 17000000\n",
      "34 loaded pd dataframe\n",
      "Fitted lines 17500000\n",
      "35 loaded pd dataframe\n",
      "Fitted lines 18000000\n",
      "36 loaded pd dataframe\n",
      "Fitted lines 18500000\n",
      "37 loaded pd dataframe\n",
      "Fitted lines 19000000\n",
      "38 loaded pd dataframe\n",
      "Fitted lines 19500000\n",
      "39 loaded pd dataframe\n",
      "Fitted lines 20000000\n",
      "40 loaded pd dataframe\n",
      "Fitted lines 20500000\n",
      "41 loaded pd dataframe\n",
      "Fitted lines 21000000\n",
      "42 loaded pd dataframe\n",
      "Fitted lines 21500000\n",
      "43 loaded pd dataframe\n",
      "Fitted lines 22000000\n",
      "44 loaded pd dataframe\n",
      "Fitted lines 22500000\n",
      "45 loaded pd dataframe\n",
      "Fitted lines 23000000\n",
      "46 loaded pd dataframe\n",
      "Fitted lines 23500000\n",
      "47 loaded pd dataframe\n",
      "Fitted lines 24000000\n",
      "48 loaded pd dataframe\n",
      "Fitted lines 24500000\n",
      "49 loaded pd dataframe\n",
      "Fitted lines 25000000\n",
      "50 loaded pd dataframe\n",
      "Fitted lines 25500000\n",
      "51 loaded pd dataframe\n",
      "Fitted lines 26000000\n",
      "52 loaded pd dataframe\n",
      "Fitted lines 26500000\n",
      "53 loaded pd dataframe\n",
      "Fitted lines 27000000\n",
      "54 loaded pd dataframe\n",
      "Fitted lines 27500000\n",
      "55 loaded pd dataframe\n",
      "Fitted lines 28000000\n",
      "56 loaded pd dataframe\n",
      "Fitted lines 28500000\n",
      "57 loaded pd dataframe\n",
      "Fitted lines 29000000\n",
      "58 loaded pd dataframe\n",
      "Fitted lines 29500000\n",
      "59 loaded pd dataframe\n",
      "Fitted lines 30000000\n",
      "60 loaded pd dataframe\n",
      "Fitted lines 30500000\n",
      "61 loaded pd dataframe\n",
      "Fitted lines 31000000\n",
      "62 loaded pd dataframe\n",
      "Fitted lines 31500000\n",
      "63 loaded pd dataframe\n",
      "Fitted lines 32000000\n",
      "64 loaded pd dataframe\n",
      "Fitted lines 32500000\n",
      "65 loaded pd dataframe\n",
      "Fitted lines 33000000\n",
      "66 loaded pd dataframe\n",
      "Fitted lines 33500000\n",
      "67 loaded pd dataframe\n",
      "Fitted lines 34000000\n",
      "68 loaded pd dataframe\n",
      "Fitted lines 34500000\n",
      "69 loaded pd dataframe\n",
      "Fitted lines 34962162\n"
     ]
    }
   ],
   "source": [
    "minimums = {\"Airline\": 0.0, \"Year\": 2005, \"Month\": 1, \"Tail_Number\": 0, \"depAirport\": 0, \"arrAirport\": 0,  \n",
    "           \"Departure_hour\": 0, \"Departure_minute\": 0, 'PRCP': 0, 'SNOW': 0, 'TMAX': -367, 'TMIN': -439}\n",
    "maximums = {\"Airline\": 23, \"Year\": 2017, \"Month\": 12, \"Tail_Number\": 9128, \"depAirport\": 395, \"arrAirport\": 395,  \n",
    "           \"Departure_hour\": 23, \"Departure_minute\": 59, 'PRCP': 3335, 'SNOW': 465, 'TMAX': 578, 'TMIN': 556}\n",
    "\n",
    "filename = \"Final_historical_data.csv\"\n",
    "shuffle = np.random.permutation(np.arange(34962162)) #number of rows.\n",
    "print(\"Randomization order complete.\")\n",
    "model = SGDClassifier(loss = 'log', n_jobs = -1, warm_start = True)\n",
    "for i in range(34962162//500000 + 1):\n",
    "    skip = shuffle[i*500000: min((i+1)*500000, 34962162)]\n",
    "    df = pd.read_csv(filename, skiprows=skip, names = [\"Airline\", \"Year\", \"Month\", \"Day\"\n",
    "                                    ,\"Tail\", \"Source\", \"Destination\",  \"Departure_hour\", \"Departure_minute\"\n",
    "                                    , \"Delay\", \"Station\", \"Previous_Delay\", 'PRCP', 'SNOW', 'TMAX', 'TMIN'])\n",
    "    del skip\n",
    "    gc.collect()\n",
    "    print(i, \"loaded pd dataframe\")\n",
    "    df[\"Airline\"] = airlineEncoder.transform(df[\"Airline\"])\n",
    "    df['Source'] = airportEncoder.transform(df['Source'])\n",
    "    df['Destination']  = airportEncoder.transform(df['Destination'])\n",
    "    df['Tail'] = TailEncoder.transform(df['Tail'])\n",
    "    df['Y'] = df['Delay'] > 10\n",
    "    #normalization\n",
    "\n",
    "    df['Airline'] = (df['Airline'] - minimums['Airline'])/(maximums['Airline'] - minimums['Airline'])\n",
    "    df['Year'] = (df['Year'] - minimums['Year'])/(maximums['Year'] - minimums['Year'])\n",
    "    df['Month'] = (df['Month'] - minimums['Month'])/(maximums['Month'] - minimums['Month'])\n",
    "    df['Tail'] = (df['Tail'] - minimums['Tail_Number'])/(maximums['Tail_Number'] - minimums['Tail_Number'])\n",
    "    df['Source'] = (df['Source'] - minimums['depAirport'])/(maximums['depAirport'] - minimums['depAirport'])\n",
    "    df['Destination'] = (df['Destination'] - minimums['arrAirport'])/(maximums['arrAirport'] - minimums['arrAirport'])\n",
    "    df['Departure_hour'] = (df['Departure_hour'] - minimums['Departure_hour'])/(maximums['Departure_hour'] - minimums['Departure_hour'])\n",
    "    df['Departure_minute'] = (df['Departure_minute'] - minimums['Departure_minute'])/(maximums['Departure_minute'] - minimums['Departure_minute'])\n",
    "    df['PRCP'] = (df['PRCP'] - minimums['PRCP'])/(maximums['PRCP'] - minimums['PRCP'])\n",
    "    df['SNOW'] = (df['SNOW'] - minimums['SNOW'])/(maximums['SNOW'] - minimums['SNOW'])\n",
    "    df['TMAX'] = (df['TMAX'] - minimums['TMAX'])/(maximums['TMAX'] - minimums['TMAX'])\n",
    "    df['TMIN'] = (df['TMIN'] - minimums['TMIN'])/(maximums['TMIN'] - minimums['TMIN'])\n",
    "\n",
    "    model.fit(df[[\"Airline\", \"Year\", \"Month\", \"Source\", \n",
    "           \"Destination\",  \"Departure_hour\", \"Departure_minute\", 'PRCP', 'SNOW', 'TMAX', 'TMIN']], df['Y'])\n",
    "    joblib.dump(model, \"Batch_trained_model3.pkl\", protocol = 2)\n",
    "    print(\"Fitted lines\", min((i+1)*500000, 34962162))\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "minimum = df.min(numeric_only = True)\n",
    "maximum = df.max(numeric_only = True)\n",
    "print(minimum, maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batch_train_model2.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load(\"Batch_trained_model.pkl\")\n",
    "joblib.dump(model, \"Batch_train_model2.pkl\", protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airline': 0.057053980414945346, 'Year': -0.049124588862196866, 'Month': -0.014941928825090905, 'Source': -0.16963852127306547, 'Destination': -0.029645540205650391, 'Departure_hour': 2.0954838630434307, 'Departure_minute': 0.19009012930179284, 'PRCP': 3.6506510700692814, 'SNOW': 1.586307027576932, 'TMAX': -1.7795258342986453, 'TMIN': 1.2848025970450985}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keys = [\"Airline\", \"Year\", \"Month\", \"Source\", \"Destination\",  \"Departure_hour\", \"Departure_minute\", 'PRCP', 'SNOW', 'TMAX', 'TMIN']\n",
    "values = model.coef_[0]\n",
    "d = dict(zip(keys, values))\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
